# =============================================================================
# AI Agent HA - Optimiert für Claude Sonnet 3.7, GPT-5 und Gemini 2.5
# =============================================================================
# Diese Konfiguration setzt den Agenten primär auf Claude Sonnet 3.7 und
# ermöglicht Fallback auf OpenAI (GPT-5/o3-mini) oder Gemini (2.5/2.0)
#
# WICHTIG: API-Keys in secrets.yaml speichern!
# =============================================================================

ai_agent_ha:
  # Standard-Provider (empfohlen: anthropic für beste Automation-Qualität)
  ai_provider: anthropic
  
  # API-Tokens (aus secrets.yaml)
  anthropic_token: !secret anthropic_api_key
  openai_token: !secret openai_api_key
  gemini_token: !secret gemini_api_key
  openrouter_token: !secret openrouter_api_key
  
  # Optional: Lokaler Provider (z.B. Ollama)
  # local_url: "http://localhost:11434/api/generate"
  
  # Model-Konfiguration (optional, überschreibt Defaults)
  models:
    # Claude Sonnet 3.7 (primär empfohlen)
    anthropic: "claude-3-7-sonnet-latest"  # oder "claude-3-5-sonnet-20241022"
    
    # OpenAI GPT-5/o3-mini (vollständig kompatibel)
    openai: "gpt-4o-mini"  # oder "gpt-5", "o3-mini", "gpt-4-turbo"
    
    # Google Gemini 2.5 (experimentell)
    gemini: "gemini-2.0-flash-exp"  # oder "gemini-2.5-pro-exp", "gemini-1.5-pro"
    
    # OpenRouter (Zugriff auf alle Modelle)
    openrouter: "anthropic/claude-3.7-sonnet"  # oder beliebiges Modell
    
    # Lokales Modell (falls local_url gesetzt)
    # local: "llama3.2"

# =============================================================================
# secrets.yaml Beispiel:
# =============================================================================
# anthropic_api_key: "sk-ant-api03-xyz..."
# openai_api_key: "sk-proj-xyz..."
# gemini_api_key: "AIzaSy..."
# openrouter_api_key: "sk-or-v1-xyz..."

# =============================================================================
# Verwendung im Frontend:
# =============================================================================
# 1. Sidebar öffnen ? "AI Agent HA"
# 2. Provider-Dropdown im Input-Footer nutzen
# 3. Prompt eingeben, z.B.:
#    "Erstelle eine Präsenz-Licht-Automation für das Wohnzimmer mit 
#     binary_sensor.presence_sensor_fp2_* und 
#     sensor.*light_level. Mode: restart. Als automation_suggestion."
# 4. Bei "Approve" wird Automation direkt in automations.yaml erstellt

# =============================================================================
# Empfohlene Prompts für Claude Sonnet 3.7:
# =============================================================================
# - "Optimiere die Rollladensteuerung: tagsüber blendreduktion per LUX + 
#    Sonnenstand, abends schließen; nutze cover.*, sensor.openweathermap_*, 
#    sensor.*light_level, sun.sun. Als automation_suggestion."
#
# - "Erstelle eine Gute-Nacht-Routine: alle light.* aus, Medien aus, 
#    cover.* schließen, Benachrichtigung senden. Trigger: 22:30 Uhr. 
#    Als automation_suggestion."
#
# - "Präsenzlicht tags/abends im Computerraum mit 
#    binary_sensor.presence_sensor_fp2_*, Helligkeit über 
#    sensor.presence_sensor_fp2_f9cf_light_sensor_light_level, 
#    Sicherheits-Timeouts, Modus restart. Als automation_suggestion."

# =============================================================================
# Tipps:
# =============================================================================
# - Claude Sonnet 3.7: Beste JSON-Struktur-Einhaltung, längster Context (200k)
# - GPT-5/o3-mini: Automatische Sonderbehandlung (max_completion_tokens, 
#                  deaktivierte temperature/top_p)
# - Gemini 2.5: Experimentell, niedrige Kosten, hoher Context (1M+)
# - Multi-Provider: Konfiguriere alle, wähle im UI je nach Aufgabe
# - Timeout: Bei komplexen Aufgaben 120s (Anthropic), 300s (OpenAI/Gemini)
